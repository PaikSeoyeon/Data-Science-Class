{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATUS: Opening website\n",
      "STATUS: Signing in\n",
      "STATUS: Searching for people\n",
      "\n",
      "STATUS: Scraping Page 40\n",
      "STATUS: Scraping Profile_ID: sumanthdamarla\n",
      "post id:  5dca3faf055bfd090ffcc9cc\n",
      "STATUS: Scraping Profile_ID: shreya-m-shetty-70135565\n",
      "No Skills\n",
      "post id:  5dca3fb8055bfd090ffcc9ce\n",
      "STATUS: Scraping Profile_ID: fangfang-lee\n",
      "No Skills\n",
      "post id:  5dca3fc1055bfd090ffcc9d0\n",
      "STATUS: Scraping Profile_ID: qilanma\n",
      "No Skills\n",
      "post id:  5dca3fca055bfd090ffcc9d2\n",
      "STATUS: Scraping Profile_ID: shikhaaggarwal1\n",
      "No Skills\n",
      "post id:  5dca3fd3055bfd090ffcc9d4\n",
      "STATUS: Scraping Profile_ID: karthikvenkatesan\n",
      "No Skills\n",
      "post id:  5dca3fde055bfd090ffcc9d6\n",
      "STATUS: Scraping Profile_ID: adiquet\n",
      "No Skills\n",
      "post id:  5dca3fe7055bfd090ffcc9d8\n",
      "STATUS: Scraping Profile_ID: venmora\n",
      "No Skills\n",
      "post id:  5dca3ff0055bfd090ffcc9da\n",
      "STATUS: Scraping Profile_ID: hardikbhatia\n",
      "No Skills\n",
      "post id:  5dca3ffb055bfd090ffcc9dc\n",
      "STATUS: Scraping Profile_ID: rohanoswal94\n",
      "No Skills\n",
      "post id:  5dca4004055bfd090ffcc9de\n",
      "STATUS: Scraping Page 41\n",
      "STATUS: Scraping Profile_ID: naveenrajkurapati\n",
      "No Skills\n",
      "post id:  5dca4018055bfd090ffcc9e0\n",
      "STATUS: Scraping Profile_ID: anthonywilson2\n",
      "No Skills\n",
      "post id:  5dca4023055bfd090ffcc9e2\n",
      "STATUS: Scraping Profile_ID: monikakrajnc\n",
      "No Skills\n",
      "post id:  5dca402e055bfd090ffcc9e4\n",
      "STATUS: Scraping Profile_ID: krutikadeshpande\n",
      "No Skills\n",
      "post id:  5dca4038055bfd090ffcc9e6\n",
      "STATUS: Scraping Profile_ID: todd-cook-5219495\n",
      "No Skills\n",
      "post id:  5dca4043055bfd090ffcc9e8\n",
      "STATUS: Scraping Profile_ID: amber-zhuoqi-he\n",
      "No Skills\n",
      "post id:  5dca404d055bfd090ffcc9ea\n",
      "STATUS: Scraping Profile_ID: svetlana-karaslavova-6765a7b\n",
      "No Skills\n",
      "post id:  5dca4057055bfd090ffcc9ec\n",
      "STATUS: Scraping Profile_ID: najeeb-arafat-m-0b9425125\n",
      "No Skills\n",
      "post id:  5dca4071055bfd090ffcc9ee\n",
      "STATUS: Scraping Profile_ID: vijayupadhyayuladataanalytics\n",
      "No Skills\n",
      "post id:  5dca407b055bfd090ffcc9f0\n",
      "STATUS: Scraping Profile_ID: andrew-lange-191b9695\n",
      "No Skills\n",
      "post id:  5dca4085055bfd090ffcc9f2\n",
      "STATUS: Scraping Page 42\n",
      "STATUS: Scraping Profile_ID: sonamk\n",
      "No Skills\n",
      "post id:  5dca409c055bfd090ffcc9f4\n",
      "STATUS: Scraping Profile_ID: madhuri-seela-b6835552\n",
      "No Skills\n",
      "post id:  5dca40a5055bfd090ffcc9f6\n",
      "STATUS: Scraping Profile_ID: richa-singhal\n",
      "No Skills\n",
      "post id:  5dca40b7055bfd090ffcc9f8\n",
      "STATUS: Scraping Profile_ID: swati-jain-4data\n",
      "No Skills\n",
      "post id:  5dca40c0055bfd090ffcc9fa\n",
      "STATUS: Scraping Profile_ID: chetanip\n",
      "No Skills\n",
      "post id:  5dca40c9055bfd090ffcc9fc\n",
      "STATUS: Scraping Profile_ID: nikhilgurram97\n",
      "No Skills\n",
      "post id:  5dca40d3055bfd090ffcc9fe\n",
      "STATUS: Scraping Profile_ID: pratik-parija\n",
      "No Skills\n",
      "post id:  5dca40df055bfd090ffcca00\n",
      "STATUS: Scraping Profile_ID: chelseasmith89\n",
      "No Skills\n",
      "post id:  5dca40e8055bfd090ffcca02\n",
      "STATUS: Scraping Profile_ID: sumeet-birla\n",
      "No Skills\n",
      "post id:  5dca40f5055bfd090ffcca04\n",
      "STATUS: Scraping Profile_ID: ahmed-abdelmohsen\n",
      "No Skills\n",
      "post id:  5dca4117055bfd090ffcca06\n",
      "STATUS: Scraping Page 43\n",
      "STATUS: Scraping Profile_ID: sibanisankar-nayak\n",
      "No Skills\n",
      "post id:  5dca412b055bfd090ffcca08\n",
      "STATUS: Scraping Profile_ID: patelpallav\n",
      "No Skills\n",
      "post id:  5dca4134055bfd090ffcca0a\n",
      "STATUS: Scraping Profile_ID: mukai-nong-276391b0\n",
      "No Skills\n",
      "post id:  5dca413e055bfd090ffcca0c\n",
      "STATUS: Scraping Profile_ID: ryan-delgado-69544568\n",
      "No Skills\n",
      "post id:  5dca4149055bfd090ffcca0e\n",
      "STATUS: Scraping Profile_ID: manasa-vadrevu-01800582\n",
      "No Skills\n",
      "post id:  5dca4171055bfd090ffcca10\n",
      "STATUS: Scraping Profile_ID: williamjin\n",
      "No Skills\n",
      "post id:  5dca417b055bfd090ffcca12\n",
      "STATUS: Scraping Profile_ID: jimbricker\n",
      "No Skills\n",
      "post id:  5dca4187055bfd090ffcca14\n",
      "STATUS: Scraping Profile_ID: eng1n33r\n",
      "No Skills\n",
      "post id:  5dca4190055bfd090ffcca16\n",
      "STATUS: Scraping Profile_ID: mijailgomez\n",
      "No Skills\n",
      "post id:  5dca4199055bfd090ffcca18\n",
      "STATUS: Scraping Profile_ID: prateekmane\n",
      "No Skills\n",
      "post id:  5dca41a3055bfd090ffcca1a\n",
      "STATUS: Scraping Page 44\n",
      "STATUS: Scraping Profile_ID: yared-shewarade-378aa414b\n",
      "No Skills\n",
      "post id:  5dca41b6055bfd090ffcca1c\n",
      "STATUS: Scraping Profile_ID: katiemacias\n",
      "No Skills\n",
      "post id:  5dca41c1055bfd090ffcca1e\n",
      "STATUS: Scraping Profile_ID: nitinmathur777\n",
      "No Skills\n",
      "post id:  5dca41cc055bfd090ffcca20\n",
      "STATUS: Scraping Profile_ID: alexbohr\n",
      "No Skills\n",
      "post id:  5dca41d5055bfd090ffcca22\n",
      "STATUS: Scraping Profile_ID: bhargavi-reddy-dokuru-4aa2449a\n",
      "No Skills\n",
      "post id:  5dca41f3055bfd090ffcca24\n",
      "STATUS: Scraping Profile_ID: kalyamechow\n",
      "post id:  5dca41fd055bfd090ffcca26\n",
      "STATUS: Scraping Profile_ID: samarpan-srivastav-a134942\n",
      "post id:  5dca420a055bfd090ffcca28\n",
      "STATUS: Scraping Profile_ID: syedomerw\n",
      "post id:  5dca4215055bfd090ffcca2a\n",
      "STATUS: Scraping Profile_ID: samhitakarnati\n",
      "post id:  5dca4221055bfd090ffcca2c\n",
      "STATUS: Scraping Profile_ID: francis-ho-5b2b5b1\n",
      "post id:  5dca422f055bfd090ffcca2e\n",
      "STATUS: Scraping Page 45\n",
      "STATUS: Scraping Profile_ID: jackmartin2\n",
      "post id:  5dca424c055bfd090ffcca30\n",
      "STATUS: Scraping Profile_ID: austinbennett\n",
      "post id:  5dca4258055bfd090ffcca32\n",
      "STATUS: Scraping Profile_ID: kenton-b-a7163589\n",
      "No Skills\n",
      "post id:  5dca4263055bfd090ffcca34\n",
      "STATUS: Scraping Profile_ID: tejus-prasad\n",
      "post id:  5dca426f055bfd090ffcca36\n",
      "STATUS: Scraping Profile_ID: kalyani-polagani-1335a676\n",
      "post id:  5dca427c055bfd090ffcca38\n",
      "STATUS: Scraping Profile_ID: marconaylon\n",
      "post id:  5dca4289055bfd090ffcca3a\n",
      "STATUS: Scraping Profile_ID: prasadravilla\n",
      "post id:  5dca4296055bfd090ffcca3c\n",
      "STATUS: Scraping Profile_ID: steven-yy-zhou\n",
      "post id:  5dca42a2055bfd090ffcca3e\n",
      "STATUS: Scraping Profile_ID: pooja-gupta-big-data\n",
      "post id:  5dca42ac055bfd090ffcca40\n",
      "STATUS: Scraping Profile_ID: monica-27\n",
      "post id:  5dca42b9055bfd090ffcca42\n",
      "STATUS: Scraping Page 46\n",
      "STATUS: Scraping Profile_ID: ramkumar-karunanidhi-48b0a118\n",
      "post id:  5dca42d0055bfd090ffcca44\n",
      "STATUS: Scraping Profile_ID: katluna\n",
      "post id:  5dca42e0055bfd090ffcca46\n",
      "STATUS: Scraping Profile_ID: evanfrisch\n",
      "No Skills\n",
      "post id:  5dca42e5055bfd090ffcca48\n",
      "STATUS: Scraping Profile_ID: manalighosh\n",
      "post id:  5dca4328055bfd090ffcca4a\n",
      "STATUS: Scraping Profile_ID: manisha-prathi-9411b2a2\n",
      "post id:  5dca4335055bfd090ffcca4c\n",
      "STATUS: Scraping Profile_ID: dimplechheda\n",
      "post id:  5dca433f055bfd090ffcca4e\n",
      "STATUS: Scraping Profile_ID: davidoh0905\n",
      "post id:  5dca434c055bfd090ffcca50\n",
      "STATUS: Scraping Profile_ID: srivigneshkn\n",
      "post id:  5dca435c055bfd090ffcca52\n",
      "STATUS: Scraping Profile_ID: truonghoanglinh\n",
      "post id:  5dca436f055bfd090ffcca54\n",
      "STATUS: Scraping Profile_ID: sameersuman\n",
      "post id:  5dca437c055bfd090ffcca56\n",
      "STATUS: Scraping Page 47\n",
      "STATUS: Scraping Profile_ID: anita-chen-47513637\n",
      "post id:  5dca4390055bfd090ffcca58\n",
      "STATUS: Scraping Profile_ID: surya-pasumarthi-384a098b\n",
      "post id:  5dca439b055bfd090ffcca5a\n",
      "STATUS: Scraping Profile_ID: joshuajodesty\n",
      "post id:  5dca43c8055bfd090ffcca5c\n",
      "STATUS: Scraping Profile_ID: sandeep-vutukuri-40b73299\n",
      "post id:  5dca43d4055bfd090ffcca5e\n",
      "STATUS: Scraping Profile_ID: arpitacharya\n",
      "post id:  5dca43e0055bfd090ffcca60\n",
      "STATUS: Scraping Profile_ID: nanayawessuman\n",
      "post id:  5dca43f0055bfd090ffcca62\n",
      "STATUS: Scraping Profile_ID: kyung-seop-kim-a4a31a1\n",
      "post id:  5dca43fc055bfd090ffcca64\n",
      "STATUS: Scraping Profile_ID: zzztimbo\n",
      "post id:  5dca4407055bfd090ffcca66\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: dataisbig\n",
      "post id:  5dca441a055bfd090ffcca68\n",
      "STATUS: Scraping Page 48\n",
      "STATUS: Scraping Profile_ID: ankitsarraf\n",
      "post id:  5dca4435055bfd090ffcca6a\n",
      "STATUS: Scraping Profile_ID: saulcruz\n",
      "post id:  5dca4443055bfd090ffcca6c\n",
      "STATUS: Scraping Profile_ID: pprabaka\n",
      "post id:  5dca445f055bfd090ffcca6e\n",
      "STATUS: Scraping Profile_ID: katreameya\n",
      "post id:  5dca4474055bfd090ffcca70\n",
      "STATUS: Scraping Profile_ID: harshavardhan18\n",
      "post id:  5dca447f055bfd090ffcca72\n",
      "STATUS: Scraping Profile_ID: hasanmasood\n",
      "post id:  5dca448f055bfd090ffcca74\n",
      "STATUS: Scraping Profile_ID: balakishore-kunamneni-58139324\n",
      "post id:  5dca449b055bfd090ffcca76\n",
      "STATUS: Scraping Profile_ID: alisa-aylward-266aa3a1\n",
      "post id:  5dca44a9055bfd090ffcca78\n",
      "STATUS: Scraping Profile_ID: alonhonig\n",
      "No Skills\n",
      "post id:  5dca44b7055bfd090ffcca7a\n",
      "STATUS: Scraping Profile_ID: punniya-dharshan-ganesan\n",
      "post id:  5dca44c5055bfd090ffcca7c\n",
      "STATUS: Scraping Page 49\n",
      "STATUS: Scraping Profile_ID: andrewipark\n",
      "post id:  5dca44df055bfd090ffcca7e\n",
      "STATUS: Scraping Profile_ID: rajanirath\n",
      "post id:  5dca44eb055bfd090ffcca80\n",
      "STATUS: Scraping Profile_ID: siddharthanand\n",
      "post id:  5dca4500055bfd090ffcca82\n",
      "STATUS: Scraping Profile_ID: ken-hu-5016b63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post id:  5dca450d055bfd090ffcca84\n",
      "STATUS: Scraping Profile_ID: sharathchandra1288\n",
      "post id:  5dca451d055bfd090ffcca86\n",
      "STATUS: Scraping Profile_ID: stephanie-toper-5007b76\n",
      "post id:  5dca452a055bfd090ffcca88\n",
      "STATUS: Scraping Profile_ID: snehalbshinde\n",
      "post id:  5dca4537055bfd090ffcca8a\n",
      "STATUS: Scraping Profile_ID: tedhallum\n",
      "post id:  5dca4547055bfd090ffcca8c\n",
      "STATUS: Scraping Profile_ID: bilind-h-5799b530\n",
      "post id:  5dca4552055bfd090ffcca8e\n",
      "STATUS: Scraping Profile_ID: dayue\n",
      "post id:  5dca455e055bfd090ffcca90\n",
      "STATUS: Scraping Page 50\n",
      "STATUS: Scraping Profile_ID: stephanwarren\n",
      "post id:  5dca457b055bfd090ffcca92\n",
      "STATUS: Scraping Profile_ID: nataliya\n",
      "post id:  5dca4593055bfd090ffcca94\n",
      "STATUS: Scraping Profile_ID: ayan-ray-90331466\n",
      "post id:  5dca45af055bfd090ffcca96\n",
      "STATUS: Scraping Profile_ID: mohit-galvankar\n",
      "post id:  5dca45bb055bfd090ffcca98\n",
      "STATUS: Scraping Profile_ID: sandy-willbanks-76379a4\n",
      "post id:  5dca45c8055bfd090ffcca9a\n",
      "STATUS: Scraping Profile_ID: danrmonty\n",
      "post id:  5dca45db055bfd090ffcca9c\n",
      "STATUS: Scraping Profile_ID: aadig\n",
      "post id:  5dca45ec055bfd090ffcca9e\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: zohreh-baharvand-irannia\n",
      "post id:  5dca461f055bfd090ffccaa0\n",
      "STATUS: Scraping Profile_ID: ankitrajsaxena\n",
      "post id:  5dca462e055bfd090ffccaa2\n",
      "STATUS: Scraping Page 51\n",
      "STATUS: Scraping Profile_ID: aeri-panchal-0003aa158\n",
      "No Skills\n",
      "post id:  5dca4644055bfd090ffccaa4\n",
      "STATUS: Scraping Profile_ID: brett-bevers-5438b945\n",
      "post id:  5dca4652055bfd090ffccaa6\n",
      "STATUS: Scraping Profile_ID: biltahir\n",
      "post id:  5dca4662055bfd090ffccaa8\n",
      "STATUS: Scraping Profile_ID: chetmancini\n",
      "post id:  5dca4671055bfd090ffccaaa\n",
      "STATUS: Scraping Profile_ID: alec-williams-22372568\n",
      "post id:  5dca4681055bfd090ffccaac\n",
      "STATUS: Scraping Profile_ID: matthewropp\n",
      "post id:  5dca468e055bfd090ffccaae\n",
      "STATUS: Scraping Profile_ID: nikolayvoronchikhin\n",
      "post id:  5dca46a3055bfd090ffccab0\n",
      "STATUS: Scraping Profile_ID: deeptaanshu\n",
      "post id:  5dca46b0055bfd090ffccab2\n",
      "STATUS: Scraping Profile_ID: adam-boscarino-47267313\n",
      "post id:  5dca46cc055bfd090ffccab4\n",
      "STATUS: Scraping Profile_ID: tnguyen91\n",
      "post id:  5dca46db055bfd090ffccab6\n",
      "STATUS: Scraping Page 52\n",
      "STATUS: Scraping Profile_ID: jaewoopark91\n",
      "post id:  5dca46f7055bfd090ffccab8\n",
      "STATUS: Scraping Profile_ID: sierrapark\n",
      "post id:  5dca4703055bfd090ffccaba\n",
      "STATUS: Scraping Profile_ID: zhining-zhou\n",
      "post id:  5dca4710055bfd090ffccabc\n",
      "STATUS: Scraping Profile_ID: christineding\n",
      "post id:  5dca471d055bfd090ffccabe\n",
      "STATUS: Scraping Profile_ID: shansusielu\n",
      "post id:  5dca4729055bfd090ffccac0\n",
      "STATUS: Scraping Profile_ID: amr-ghanem-1b073a16\n",
      "post id:  5dca474f055bfd090ffccac2\n",
      "STATUS: Scraping Profile_ID: josh-tennefoss-79051261\n",
      "post id:  5dca475a055bfd090ffccac4\n",
      "STATUS: Scraping Profile_ID: dhirajgupta\n",
      "post id:  5dca4766055bfd090ffccac6\n",
      "STATUS: Scraping Profile_ID: malikankur\n",
      "No Skills\n",
      "post id:  5dca4773055bfd090ffccac8\n",
      "STATUS: Scraping Profile_ID: vamshi-k-a5880478\n",
      "post id:  5dca4781055bfd090ffccaca\n",
      "STATUS: Scraping Page 53\n",
      "STATUS: Scraping Profile_ID: elizabeth-lee-a97727a1\n",
      "post id:  5dca47a5055bfd090ffccacc\n",
      "STATUS: Scraping Profile_ID: pradeep-enabothula-b73b34b0\n",
      "post id:  5dca47b9055bfd090ffccace\n",
      "STATUS: Scraping Profile_ID: tarunreddygaddam\n",
      "post id:  5dca47c5055bfd090ffccad0\n",
      "STATUS: Scraping Profile_ID: nigon-yang-5a86b92a\n",
      "post id:  5dca47d3055bfd090ffccad2\n",
      "STATUS: Scraping Profile_ID: arjit\n",
      "post id:  5dca47e0055bfd090ffccad4\n",
      "STATUS: Scraping Profile_ID: teng-emma-c-95363677\n",
      "post id:  5dca47fe055bfd090ffccad6\n",
      "STATUS: Scraping Profile_ID: avy-ali-363882188\n",
      "post id:  5dca4852055bfd090ffccad8\n",
      "STATUS: Scraping Profile_ID: sauravmazumdar-b2b18414\n",
      "post id:  5dca4861055bfd090ffccada\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: leah-mcguire-70a27047\n",
      "post id:  5dca48a7055bfd090ffccadc\n",
      "STATUS: Scraping Page 54\n",
      "STATUS: Scraping Profile_ID: srikanthr341\n",
      "post id:  5dca48c2055bfd090ffccade\n",
      "STATUS: Scraping Profile_ID: dustinvannoy\n",
      "post id:  5dca48cf055bfd090ffccae0\n",
      "STATUS: Scraping Profile_ID: yaobjtu\n",
      "post id:  5dca48dc055bfd090ffccae2\n",
      "STATUS: Scraping Profile_ID: neelima-gaddam-a6a69621\n",
      "post id:  5dca48e8055bfd090ffccae4\n",
      "STATUS: Scraping Profile_ID: keith-mascarenhas\n",
      "post id:  5dca48f6055bfd090ffccae6\n",
      "STATUS: Scraping Profile_ID: stella-zhao-12432944\n",
      "post id:  5dca4902055bfd090ffccae8\n",
      "STATUS: Scraping Profile_ID: danliluo\n",
      "post id:  5dca493a055bfd090ffccaea\n",
      "STATUS: Scraping Profile_ID: yidiwang\n",
      "post id:  5dca4948055bfd090ffccaec\n",
      "STATUS: Scraping Profile_ID: vkettmann\n",
      "post id:  5dca4955055bfd090ffccaee\n",
      "STATUS: Scraping Profile_ID: dorriswong\n",
      "post id:  5dca4962055bfd090ffccaf0\n",
      "STATUS: Scraping Page 55\n",
      "STATUS: Scraping Profile_ID: kalmanchapman\n",
      "post id:  5dca4977055bfd090ffccaf2\n",
      "STATUS: Scraping Profile_ID: soumya-k-pydev\n",
      "post id:  5dca4980055bfd090ffccaf4\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: syadlapalli\n",
      "post id:  5dca4991055bfd090ffccaf6\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: kishorekumarkuruguntla\n",
      "post id:  5dca49cf055bfd090ffccaf8\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: pallavi-naidu\n",
      "post id:  5dca49e5055bfd090ffccafa\n",
      "STATUS: Scraping Profile_ID: sisi-gu-678a5047\n",
      "post id:  5dca49f1055bfd090ffccafc\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Page 56\n",
      "STATUS: Scraping Profile_ID: jayaprakash-kasinathan\n",
      "post id:  5dca4a84055bfd090ffccafe\n",
      "STATUS: Scraping Profile_ID: anthonywyso\n",
      "post id:  5dca4a91055bfd090ffccb00\n",
      "STATUS: Scraping Profile_ID: snorderhaug\n",
      "post id:  5dca4ac4055bfd090ffccb02\n",
      "STATUS: Scraping Profile_ID: ikradarsh\n",
      "post id:  5dca4ad2055bfd090ffccb04\n",
      "STATUS: Skipping Profile_ID: people\n",
      "STATUS: Scraping Profile_ID: ahmedhamdyse\n",
      "post id:  5dca4ae8055bfd090ffccb06\n",
      "STATUS: Scraping Profile_ID: kashyapuppuluri\n",
      "post id:  5dca4af6055bfd090ffccb08\n",
      "STATUS: Scraping Profile_ID: karthik-kannan-01747737\n",
      "post id:  5dca4b18055bfd090ffccb0a\n",
      "STATUS: Scraping Profile_ID: naveen-kumar-bandi-02818668\n",
      "post id:  5dca4b28055bfd090ffccb0c\n",
      "STATUS: Scraping Profile_ID: siva-prasad-b-b6129837\n",
      "post id:  5dca4b35055bfd090ffccb0e\n",
      "STATUS: Scraping Page 57\n",
      "STATUS: Scraping Profile_ID: tmacey\n",
      "post id:  5dca4b6a055bfd090ffccb10\n",
      "STATUS: Scraping Profile_ID: slava-guszin-5b7737\n",
      "post id:  5dca4b7a055bfd090ffccb12\n",
      "STATUS: Scraping Profile_ID: kamalapriya-anandaraman-akp1610\n",
      "post id:  5dca4b8a055bfd090ffccb14\n",
      "STATUS: Scraping Profile_ID: cindyxinchen\n",
      "post id:  5dca4b9a055bfd090ffccb16\n",
      "STATUS: Scraping Profile_ID: gaurav-dasson-13b77b97\n",
      "post id:  5dca4bc6055bfd090ffccb18\n",
      "STATUS: Scraping Profile_ID: shiv-prasad-8157b617\n",
      "post id:  5dca4bd7055bfd090ffccb1a\n",
      "STATUS: Scraping Profile_ID: rnavina\n",
      "post id:  5dca4be6055bfd090ffccb1c\n",
      "STATUS: Scraping Profile_ID: umauppin\n",
      "post id:  5dca4c07055bfd090ffccb1e\n",
      "STATUS: Scraping Profile_ID: nidhi-gupta-5b80874\n",
      "post id:  5dca4c14055bfd090ffccb20\n",
      "STATUS: Scraping Profile_ID: anil-thadanii\n",
      "post id:  5dca4c20055bfd090ffccb22\n",
      "Daily automation has been completed for: get_people.py\n",
      "Check docnum.txt for # of documents submitted!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov  9 17:29:50 2019\n",
    "\n",
    "@author: Sungmin Hong\n",
    "\"\"\"\n",
    "#%%\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#%%\n",
    "# Global Variable\n",
    "docNum = 0\n",
    "#%%\n",
    "# REPLACE With your LinkedIn Credentials\n",
    "USERNAME = \"\"\n",
    "PASSWORD = \"\"\n",
    "#%%\n",
    "def mongodb_init():\n",
    "    client=MongoClient('mongodb://localhost')\n",
    "    db=client.smartcareer\n",
    "    return db\n",
    "#%%\n",
    "def mongodb_get_collection(db,item):\n",
    "    col=db[item]\n",
    "    return col\n",
    "#%%\n",
    "def mongodb_put_doc(doc):\n",
    "    db=mongodb_init()\n",
    "    col=mongodb_get_collection(db,'dataengineer')\n",
    "\n",
    "    try:\n",
    "        global docNum\n",
    "        re=col.insert_one(doc)\n",
    "        ret=re.inserted_id    ##re에 id 번호 부여하는 것?\n",
    "        docNum += 1\n",
    "    except:\n",
    "        ret=doc['ProfileID']\n",
    "          \n",
    "    return ret\n",
    "#%%\n",
    "def clean_item(item):\n",
    "    item = item.replace('\\n', ' ')\n",
    "    item = item.strip()\n",
    "    return item\n",
    "#%%\n",
    "# https://www.linkedin.com/search/results/people/?facetGeoRegion=%5B%22us%3A0%22%5D&keywords=Data%20Engineer&origin=FACETED_SEARCH\n",
    "#검색하고자 하는 정보를 title를 넣어 기본 검색 URL을 만든다.\n",
    "# 잡타이틀 정보에 불필요한 공백, 특수문자를 제거한다.\n",
    "# 내가 가져올 url을 넘겨준다. scrape_url\n",
    "def generate_scrape_url(scrape_url, config):\n",
    "\n",
    "    title = config['Job Title']  ## config는 cfg.json전체 정보.\n",
    "\n",
    "# collecting people in US only\n",
    "    scrape_url += \"/search/results/people/?facetGeoRegion=%5B%22us%3A0%22%5D&keywords=\"\n",
    "    scrape_url += title\n",
    "    scrape_url += \"&origin=SWITCH_SEARCH_VERTICAL&page=40\"\n",
    "\n",
    "\n",
    "    valid_title_name = title.strip().replace(' ', '_')\n",
    "    valid_title_name = re.sub(r'(?u)[^-\\w.]', '', valid_title_name) #means 첫번째를 2번째로 바꾼다. valid_title_name에서\n",
    "\n",
    "    return scrape_url\n",
    "#%%\n",
    "def scroll_down_page(browser, speed=8): \n",
    "    current_scroll_position, new_height = 0, 1\n",
    "    while current_scroll_position <= new_height:\n",
    "        current_scroll_position += speed\n",
    "        browser.execute_script(\"window.scrollTo(0, {});\".format(current_scroll_position))\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "#%%\n",
    "def pscrape(config):\n",
    "    start_time = time.time()\n",
    "    # driver download: https://github.com/mozilla/geckodriver/releases\n",
    "    # windows \\, Linux and Max /\n",
    "    driver = os.getcwd() + \"/geckodriver.exe\"\n",
    "    base_url = \"https://www.linkedin.com\"\n",
    "    sign_in_url = \"https://www.linkedin.com/uas/login?fromSignIn=true\"\n",
    "    people_data = []\n",
    "    page = 40\n",
    "\n",
    "    USERNAME = config['User Name']\n",
    "    PASSWORD = config['Password']\n",
    "    col=config['Collection']\n",
    "    \n",
    "    # 주어진 json파일정보로 검색 url을 얻기\n",
    "    people_search_url = generate_scrape_url(base_url, config)\n",
    "\n",
    "    # 해당 URL 로 이동 (로그인 페이지 이동)\n",
    "    print('\\nSTATUS: Opening website')\n",
    "    browser = webdriver.Firefox(executable_path=driver)  ##내가 Firefox에서 Chrome으로 바꿈\n",
    "    browser.get(sign_in_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "\n",
    "    # 해당 페이지에서 유저명과 패스워드를 입력.\n",
    "    print('STATUS: Signing in')\n",
    "    browser.find_element_by_id('username').send_keys(USERNAME)\n",
    "    time.sleep(random.randint(1,3))\n",
    "\n",
    "    browser.find_element_by_id('password').send_keys(PASSWORD)\n",
    "    time.sleep(random.randint(1,3))\n",
    "\n",
    "    # 로그인 버튼 클릭\n",
    "    browser.find_element_by_class_name('login__form_action_container ').click()\n",
    "    time.sleep(random.randint(1,3))\n",
    " \n",
    "    # 로그인 이후에 json에 주어진 jobtitle로 검색을 수행한다. 수행 후, 스크롤해주기\n",
    "    print('STATUS: Searching for people\\n')\n",
    "    browser.get(people_search_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    scroll_down_page(browser, 4)\n",
    "\n",
    "    # 사람 정보 위치(아마도)\n",
    "    people = browser.find_elements_by_xpath('//div[@class=\"search-result__info pt3 pb4 ph0\"]')\n",
    "\n",
    "    \n",
    "    if len(people) == 0:  # 만약 원하는 위치에 정보가 없으면\n",
    "        print('STATUS: No people found. Press any key to exit scraper')\n",
    "        print(\"Check docnum.txt for # of documents submitted!\")\n",
    "        # docnum.txt를 만들어서(또는 열어서) 정보를 써준다.\n",
    "        today = datetime.now()\n",
    "        f = open(\"docnum1.txt\",\"w+\")  ##docnum.txt 없으면 생기고, 쓰기 기능으로(+ 조사 필요)들어놓아야 하는지? 코드와 같은 Anaconda Folder 안에-\n",
    "        f.write(\"Ran:\\n\")\n",
    "        f.write(str(today))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\nNumber of documents submitted:\\n\")\n",
    "        f.write(str(docNum))\n",
    "        f.close()\n",
    "        browser.quit()\n",
    "        exit = input('')  # 어떤 역할인지? 우선은 skip(우선은 사용하는 곳이 없어보임.)\n",
    "        sys.exit(0)  # \n",
    "\n",
    "    # 위치에 정보가 있으면\n",
    "    \n",
    "    #Scraping up to 6 pages per search.\n",
    "    While True:\n",
    "        print('\\nSTATUS: Scraping Page ' + str(page))\n",
    "        \n",
    "        # 링크가져오기\n",
    "        links = []\n",
    "        for link in people:\n",
    "            try:\n",
    "                link = link.find_element_by_class_name(\"search-result__result-link\").get_attribute(\"href\")\n",
    "                links.append(link)\n",
    "            except:\n",
    "                ()\n",
    "                \n",
    "        # 링크를 얻고 바로 그 주소로 이동.(획득한 링크만큼)\n",
    "        for link in links:\n",
    "            obj = {}  # 딕셔너리 형태로 빈 딕셔너리 생성.\n",
    "            browser.get(link)\n",
    "            time.sleep(random.randint(1,3))\n",
    "\n",
    "            # 20초동안 스크롤을 한다.\n",
    "            scroll_down_page(browser, 20)\n",
    "  \n",
    "            # 아마도, 링크안에 ProfileID 관련 정보가 있다. 그래서 그 정보를 가져오기\n",
    "            # obj : ProfileID 키 추가, \n",
    "            # case1. 값이 만약 people일 아닌 경우,\n",
    "            obj['ProfileID'] = link.split('/')[len(link.split('/'))-2]\n",
    "            if obj['ProfileID'] != \"people\":\n",
    "                print(\"STATUS: Scraping Profile_ID: {}\".format(obj['ProfileID']))\n",
    "\n",
    "                # 무언가 클릭을 두번 한다. \n",
    "                try:\n",
    "                    browser.find_element_by_xpath(\"//a[@class='lt-line-clamp__more']\").click()\n",
    "                except:\n",
    "                    ()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath(\"//button[@class='pv-profile-section__see-more-inline pv-profile-section__text-truncate-toggle link link-without-hover-state']\").click()\n",
    "                except:\n",
    "                    ()\n",
    "\n",
    "                # 어떤 요소의 Job Title를 text로 가져온다.\n",
    "                try:\n",
    "                    obj['Job Title'] = clean_item(browser.find_element_by_xpath(\"//h2[@class='mt1 t-18 t-black t-normal']\").text)\n",
    "                except:\n",
    "                    obj['Job Title'] = ''\n",
    "\n",
    "                # 어떤 요소의 Location을 가져온다. \n",
    "                try:\n",
    "                    obj['Location'] = clean_item(browser.find_element_by_xpath(\"//li[@class='t-16 t-black t-normal inline-block']\").text)\n",
    "                except:\n",
    "                    obj['Location'] = ''\n",
    "\n",
    "                # Profile Summary를 가져오기 \n",
    "                try:\n",
    "                    obj['Profile Summary'] = clean_item(browser.find_element_by_class_name(\"pv-about__summary-text\").text)\n",
    "                except:\n",
    "                    obj['Profile Summary'] = ''\n",
    "                \n",
    "                # 회사를 가져오기(근무했던 했던 회사가 아닐까?)\n",
    "                try:\n",
    "                    companies = browser.find_element_by_id(\"experience-section\").find_elements_by_class_name(\"pv-profile-section__card-item-v2\")\n",
    "                except:\n",
    "                    companies = []\n",
    "\n",
    "                experience = []\n",
    "                experience_obj = {}\n",
    "                \n",
    "                # 회사들(경력)에서 상세 정보가져오기\n",
    "                for company in companies:\n",
    "                    try:\n",
    "                        experience_obj['Job Title'] = clean_item(company.find_element_by_tag_name('h3').text)\n",
    "                    except:\n",
    "                        experience_obj['Job Title'] = ''\n",
    "\n",
    "                    try:\n",
    "                        experience_obj['Company'] = clean_item(company.find_element_by_class_name('pv-entity__secondary-title').text)\n",
    "                    except:\n",
    "                        experience_obj['Company'] = ''\n",
    "\n",
    "                    try:\n",
    "                        experience_obj['Period'] = clean_item(company.find_element_by_class_name('pv-entity__date-range').text).replace('Dates Employed ', '')\n",
    "                    except:\n",
    "                        experience_obj['Period'] = ''\n",
    "\n",
    "                    try:\n",
    "                        experience_obj['Years'] = clean_item(company.find_element_by_class_name(\"pv-entity__bullet-item-v2\").text)\n",
    "                    except:\n",
    "                        experience_obj['Years'] = ''\n",
    "\n",
    "                    try:\n",
    "                        experience_obj['Location'] = clean_item(company.find_element_by_class_name('pv-entity__location').text).replace('Location ', '')\n",
    "                    except:\n",
    "                        experience_obj['Location'] = ''\n",
    "\n",
    "                    try:\n",
    "                        experience_obj['Description'] = clean_item(company.find_element_by_class_name('pv-entity__description').text)\n",
    "                    except:\n",
    "                        experience_obj['Description'] = ''\n",
    "\n",
    "                    experience.append(experience_obj)\n",
    "                    experience_obj = {}\n",
    "\n",
    "                obj['Experience'] = experience\n",
    "\n",
    "                # 어떤 교육(대학 또는 기관)을 받았는가?\n",
    "                try:\n",
    "                    institutes = browser.find_element_by_id(\"education-section\").find_elements_by_class_name(\"pv-entity__summary-info\")\n",
    "                except:\n",
    "                    institutes = []\n",
    "\n",
    "                education = []\n",
    "                education_obj = {}\n",
    "\n",
    "                # 어떤 학교?(school) 전공일 것 같음. 아마. \n",
    "                for institute in institutes:\n",
    "                    try:\n",
    "                        education_obj['School'] = clean_item(institute.find_element_by_xpath(\"//h3[@class='pv-entity__school-name t-16 t-black t-bold']\").text)\n",
    "                    except:\n",
    "                        education_obj['School'] = ''\n",
    "\n",
    "                    try:\n",
    "                        degree_name = clean_item(institute.find_element_by_class_name('pv-entity__degree-name').text).replace('Degree Name ', '')\n",
    "                    except:\n",
    "                        degree_name = ''\n",
    "\n",
    "                    try:\n",
    "                        field_of_study = clean_item(institute.find_element_by_class_name('pv-entity__fos').text).replace('Field Of Study ', '')\n",
    "                    except:\n",
    "                        field_of_study = ''\n",
    "\n",
    "                    try:\n",
    "                        grade = clean_item(institute.find_element_by_class_name('pv-entity__grade').text).replace('Grade ', '')\n",
    "                    except:\n",
    "                        grade = ''\n",
    "\n",
    "                    education_obj['Degree'] = degree_name+' '+field_of_study+' '+grade\n",
    "\n",
    "                    try:\n",
    "                        education_obj['Date Attended'] = clean_item(institute.find_element_by_class_name('pv-entity__dates').text).replace('Dates attended or expected graduation ', '')\n",
    "                    except:\n",
    "                        education_obj['Date Attended'] = ''\n",
    "\n",
    "                    education.append(education_obj)\n",
    "                    education_obj = {}\n",
    "\n",
    "                obj['Education'] = education\n",
    "            \n",
    "                try:\n",
    "                    browser.find_element_by_xpath(\"//button[@class='pv-profile-section__card-action-bar pv-skills-section__additional-skills artdeco-container-card-action-bar artdeco-button artdeco-button--tertiary artdeco-button--3 artdeco-button--fluid']\").click()\n",
    "                except:\n",
    "                    print(\"No Skills\")\n",
    "\n",
    "                try:\n",
    "                    skill_sets = browser.find_element_by_class_name(\"pv-skill-categories-section__top-skills\").find_elements_by_class_name(\"pv-skill-category-entity__skill-wrapper\")\n",
    "                except:\n",
    "                    skill_sets = []\n",
    "\n",
    "                skills = []\n",
    "                skills_obj = {}\n",
    "\n",
    "                # 당신이 가진 기술은 (아마 확인 필요. Python, R, Spark, ...)\n",
    "                for skill_set in skill_sets:\n",
    "                    try:\n",
    "                        skills_obj['Skills'] = clean_item(skill_set.find_element_by_class_name('pv-skill-category-entity__name').text)\n",
    "                    except:\n",
    "                        skills_obj['Skills'] = ''\n",
    "\n",
    "                    skills.append(skills_obj)\n",
    "                    skills_obj = {}\n",
    "\n",
    "                obj['Skills & Endorsements'] = skills\n",
    "\n",
    "                try:\n",
    "                    all_skillsets = browser.find_elements_by_xpath(\"//div[@class='pv-skill-category-list pv-profile-section__section-info mb6 ember-view']\")\n",
    "                except:\n",
    "                    all_skillsets = []\n",
    "\n",
    "                # 스킬들에 정보를 하나씩 뽑아내기\n",
    "                for one in all_skillsets:\n",
    "                    general_skills = []\n",
    "                    try:\n",
    "                        g_skills = one.find_elements_by_class_name(\"pv-skill-category-entity\")\n",
    "                        for g_skill in g_skills:\n",
    "                            try:\n",
    "                                skills_obj['Skills'] = clean_item(\n",
    "                                    g_skill.find_element_by_class_name('pv-skill-category-entity__name').text)\n",
    "                            except:\n",
    "                                skills_obj['Skills'] = ''\n",
    "\n",
    "                            general_skills.append(skills_obj)\n",
    "                            skills_obj = {}\n",
    "                    except:\n",
    "                        general_skills = []\n",
    "\n",
    "                    try:\n",
    "                        category_name = clean_item(one.find_element_by_tag_name('h3').text)\n",
    "                    except:\n",
    "                        category_name = \"Skills\"\n",
    "\n",
    "                    obj[category_name] = general_skills\n",
    "\n",
    "                try:\n",
    "                    dateCaptured = date.today()\n",
    "                    obj['Date Captured'] = str(dateCaptured)\n",
    "                except:\n",
    "                    obj['Date Captured'] = ''\n",
    "\n",
    "                # 이제 모아진 정보 (obj에 모였음) 이를 mongodb에 넣는다.\n",
    "                people_data.append(obj)\n",
    "            \n",
    "                doc_id=mongodb_put_doc(obj)   # 넣기\n",
    "                print('post id: ', doc_id)\n",
    "            else:\n",
    "                print(\"STATUS: Skipping Profile_ID: {}\".format(obj['ProfileID']))\n",
    "\n",
    "        page += 1\n",
    "        \n",
    "        # 다음 페이지 넘기기\n",
    "        next_page = people_search_url + '&page=' + str(page)\n",
    "        browser.get(next_page)\n",
    "        time.sleep(random.randint(1,3))\n",
    "        scroll_down_page(browser, 4)\n",
    "\n",
    "\n",
    "        people = browser.find_elements_by_xpath('//div[@class=\"search-result__info pt3 pb4 ph0\"]')\n",
    "        if len(people) == 0:\n",
    "            break\n",
    "\n",
    "        # 앞의 while문에 의해서 아마 6페이지를 가져오는 소스 코드임.\n",
    "    browser.quit()\n",
    "#%%\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Reads in the config file so input is automatic.\n",
    "    with open(\"cfg.json\") as json_cfg:\n",
    "        d = json.load(json_cfg)\n",
    "    \n",
    "    jobTitle = d['Job Title']\n",
    "\n",
    "    jobList = []\n",
    "    tempStr = \"\"\n",
    "\n",
    "    pscrape(d)\n",
    "    # while len(configArray) > 0:\n",
    "    #     try:\n",
    "    #         int(configArray[0])\n",
    "    #         break\n",
    "    #     except:\n",
    "    #         jobList.append(configArray[0])\n",
    "    #         del configArray[0]\n",
    "\n",
    "    # # Searches multiple jobs in a row.\n",
    "    # for x in range(len(jobList)):\n",
    "    #     print(\"Now scraping:\", jobList[0])\n",
    "    #     pscrape(jobList[0], configArray)\n",
    "    #     time.sleep(5)\n",
    "    #     del jobList[0]\n",
    "\n",
    "    print(\"Daily automation has been completed for: get_people.py\")\n",
    "    print(\"Check docnum.txt for # of documents submitted!\")\n",
    "    today = datetime.now()\n",
    "    f = open(\"docnum.txt\",\"w+\")\n",
    "    f.write(\"Ran:\\n\")\n",
    "    f.write(str(today))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\nNumber of documents submitted:\\n\")\n",
    "    f.write(str(docNum))\n",
    "    f.close()\n",
    "\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "\n",
      "hi2\n"
     ]
    }
   ],
   "source": [
    "print('hi')\n",
    "print('\\nhi2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

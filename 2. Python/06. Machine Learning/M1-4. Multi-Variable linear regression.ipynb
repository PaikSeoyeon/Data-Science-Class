{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01. Multi-variable linear regressio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_2:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y  = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b  = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "print(hypothesis)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846bd65edf694f089cd44f4455d8e8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 8585.2041015625 \n",
      "Prediction :\n",
      "[230.84917 285.1581  276.7442  303.636   217.71155]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 2693.230712890625 \n",
      "Prediction :\n",
      "[194.67107 241.67375 233.89885 256.97836 184.54378]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 846.4093017578125 \n",
      "Prediction :\n",
      "[174.4165  217.32832 209.91138 230.85648 165.9742 ]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 267.52789306640625 \n",
      "Prediction :\n",
      "[163.07695 203.69803 196.48174 216.23181 155.57758]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 86.07921600341797 \n",
      "Prediction :\n",
      "[156.72859 196.0668  188.96307 208.04404 149.75673]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 29.204030990600586 \n",
      "Prediction :\n",
      "[153.1746  191.79422 184.75372 203.46004 146.49767]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 11.375921249389648 \n",
      "Prediction :\n",
      "[151.18509 189.40198 182.39711 200.89366 144.67284]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 5.787132740020752 \n",
      "Prediction :\n",
      "[150.07147 188.0625  181.07784 199.45686 143.65103]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 4.034646511077881 \n",
      "Prediction :\n",
      "[149.44821 187.31241 180.33926 198.65247 143.07875]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 3.4847092628479004 \n",
      "Prediction :\n",
      "[149.0995  186.89232 179.92586 198.20215 142.75818]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 3.15012788772583 \n",
      "Prediction :\n",
      "[148.70207 186.32684 179.4148  197.63486 142.31396]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 3.062218427658081 \n",
      "Prediction :\n",
      "[148.75226 186.29306 179.43091 197.64075 142.27449]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 2.9786107540130615 \n",
      "Prediction :\n",
      "[148.80113 186.2601  179.44661 197.64635 142.2361 ]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 2.8990607261657715 \n",
      "Prediction :\n",
      "[148.84879 186.22801 179.46198 197.6517  142.19885]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 2.823383331298828 \n",
      "Prediction :\n",
      "[148.89523 186.19676 179.47693 197.65681 142.16267]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 2.751343250274658 \n",
      "Prediction :\n",
      "[148.94049 186.16629 179.49153 197.66165 142.12752]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 2.682765245437622 \n",
      "Prediction :\n",
      "[148.98462 186.13663 179.5058  197.66626 142.09341]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 2.617483615875244 \n",
      "Prediction :\n",
      "[149.02762 186.10773 179.5197  197.67062 142.06029]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 2.5552978515625 \n",
      "Prediction :\n",
      "[149.06955 186.07956 179.53326 197.67477 142.02812]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 2.496086597442627 \n",
      "Prediction :\n",
      "[149.11041 186.05214 179.54652 197.67871 141.9969 ]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 2.439650774002075 \n",
      "Prediction :\n",
      "[149.15024 186.02539 179.55945 197.6824  141.96658]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 2.3858678340911865 \n",
      "Prediction :\n",
      "[149.18906 185.99933 179.57207 197.68588 141.93713]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 2.3346028327941895 \n",
      "Prediction :\n",
      "[149.22691 185.97395 179.58438 197.68918 141.90858]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 2.285708427429199 \n",
      "Prediction :\n",
      "[149.26382 185.94922 179.59642 197.69228 141.88086]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 2.239072322845459 \n",
      "Prediction :\n",
      "[149.2998  185.92511 179.60817 197.69518 141.85396]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 2.1945900917053223 \n",
      "Prediction :\n",
      "[149.33488 185.90164 179.61963 197.69789 141.82785]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 2.1521193981170654 \n",
      "Prediction :\n",
      "[149.3691  185.87875 179.63083 197.70042 141.80252]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 2.1115758419036865 \n",
      "Prediction :\n",
      "[149.40244 185.85645 179.64175 197.70276 141.77794]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 2.072849988937378 \n",
      "Prediction :\n",
      "[149.43498 185.83472 179.65245 197.70497 141.7541 ]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 2.0358617305755615 \n",
      "Prediction :\n",
      "[149.46669 185.81352 179.66287 197.70699 141.73097]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02. Multi-variable matmul linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $$ w1 x1 + w2 x2 + w3 x3 + ... + wn xn $$\n",
    "$$ [x{1} x{2} x{3}] \\times \\begin{bmatrix} w{1}\\ w{2}\\ w{3} \n",
    "\\end{bmatrix} [x_1 w_1 + x_2 w_2 + x_3 w_3] $$\n",
    "$$H(X) = XW$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56cfee6d4dc4332a0c4835a6f32609d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 13754.142578125 \n",
      "Prediction :\n",
      "[[43.244526]\n",
      " [62.632473]\n",
      " [56.235767]\n",
      " [60.108585]\n",
      " [51.52855 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 4318.98291015625 \n",
      "Prediction :\n",
      "[[ 89.02794 ]\n",
      " [117.65831 ]\n",
      " [110.454926]\n",
      " [119.15174 ]\n",
      " [ 93.49889 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 1361.555419921875 \n",
      "Prediction :\n",
      "[[114.66097]\n",
      " [148.46489]\n",
      " [140.81041]\n",
      " [152.20801]\n",
      " [116.99605]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 434.5558166503906 \n",
      "Prediction :\n",
      "[[129.01251]\n",
      " [165.71196]\n",
      " [157.80551]\n",
      " [170.71512]\n",
      " [130.15073]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 143.9869842529297 \n",
      "Prediction :\n",
      "[[137.04797]\n",
      " [175.36755]\n",
      " [167.32059]\n",
      " [181.07669]\n",
      " [137.51501]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 52.90471267700195 \n",
      "Prediction :\n",
      "[[141.5473 ]\n",
      " [180.77301]\n",
      " [172.64792]\n",
      " [186.8779 ]\n",
      " [141.63751]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 24.351261138916016 \n",
      "Prediction :\n",
      "[[144.06686]\n",
      " [183.79893]\n",
      " [175.63066]\n",
      " [190.12592]\n",
      " [143.94502]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 15.397216796875 \n",
      "Prediction :\n",
      "[[145.47803]\n",
      " [185.49265]\n",
      " [177.30077]\n",
      " [191.94449]\n",
      " [145.23639]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 12.586509704589844 \n",
      "Prediction :\n",
      "[[146.26866]\n",
      " [186.4405 ]\n",
      " [178.23595]\n",
      " [192.96277]\n",
      " [145.95886]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 11.701403617858887 \n",
      "Prediction :\n",
      "[[146.71187]\n",
      " [186.9708 ]\n",
      " [178.75972]\n",
      " [193.53302]\n",
      " [146.36284]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 10.774304389953613 \n",
      "Prediction :\n",
      "[[147.38855]\n",
      " [187.5677 ]\n",
      " [179.46027]\n",
      " [194.28535]\n",
      " [146.77301]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 10.22554874420166 \n",
      "Prediction :\n",
      "[[147.5112 ]\n",
      " [187.48338]\n",
      " [179.49754]\n",
      " [194.31473]\n",
      " [146.66032]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 9.705761909484863 \n",
      "Prediction :\n",
      "[[147.63055]\n",
      " [187.40134]\n",
      " [179.53378]\n",
      " [194.34335]\n",
      " [146.55066]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 9.213314056396484 \n",
      "Prediction :\n",
      "[[147.74666]\n",
      " [187.3215 ]\n",
      " [179.56906]\n",
      " [194.37126]\n",
      " [146.44385]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 8.74677848815918 \n",
      "Prediction :\n",
      "[[147.85965]\n",
      " [187.2438 ]\n",
      " [179.60336]\n",
      " [194.39847]\n",
      " [146.33987]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 8.30482006072998 \n",
      "Prediction :\n",
      "[[147.96957]\n",
      " [187.16817]\n",
      " [179.63672]\n",
      " [194.42497]\n",
      " [146.23865]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 7.886085510253906 \n",
      "Prediction :\n",
      "[[148.07655]\n",
      " [187.0946 ]\n",
      " [179.66922]\n",
      " [194.45085]\n",
      " [146.14009]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 7.489409446716309 \n",
      "Prediction :\n",
      "[[148.18066]\n",
      " [187.02303]\n",
      " [179.7008 ]\n",
      " [194.47607]\n",
      " [146.04416]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 7.113604545593262 \n",
      "Prediction :\n",
      "[[148.28194]\n",
      " [186.95334]\n",
      " [179.73152]\n",
      " [194.50066]\n",
      " [145.95074]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 6.757552146911621 \n",
      "Prediction :\n",
      "[[148.38046]\n",
      " [186.88553]\n",
      " [179.7614 ]\n",
      " [194.52463]\n",
      " [145.85977]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 6.420241355895996 \n",
      "Prediction :\n",
      "[[148.47636]\n",
      " [186.81958]\n",
      " [179.79048]\n",
      " [194.548  ]\n",
      " [145.77122]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 6.100643157958984 \n",
      "Prediction :\n",
      "[[148.56967]\n",
      " [186.75537]\n",
      " [179.81876]\n",
      " [194.57082]\n",
      " [145.68501]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 5.797935485839844 \n",
      "Prediction :\n",
      "[[148.66043]\n",
      " [186.69292]\n",
      " [179.84628]\n",
      " [194.59305]\n",
      " [145.60109]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 5.511074066162109 \n",
      "Prediction :\n",
      "[[148.74875]\n",
      " [186.63213]\n",
      " [179.87305]\n",
      " [194.61473]\n",
      " [145.51935]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 5.239280700683594 \n",
      "Prediction :\n",
      "[[148.8347 ]\n",
      " [186.57298]\n",
      " [179.89906]\n",
      " [194.6359 ]\n",
      " [145.43977]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 4.981808662414551 \n",
      "Prediction :\n",
      "[[148.9183 ]\n",
      " [186.51544]\n",
      " [179.92441]\n",
      " [194.65652]\n",
      " [145.36229]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 4.737872123718262 \n",
      "Prediction :\n",
      "[[148.99966]\n",
      " [186.45944]\n",
      " [179.94902]\n",
      " [194.67664]\n",
      " [145.28687]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 4.50674295425415 \n",
      "Prediction :\n",
      "[[149.0788 ]\n",
      " [186.40494]\n",
      " [179.97296]\n",
      " [194.69627]\n",
      " [145.21341]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 4.2877044677734375 \n",
      "Prediction :\n",
      "[[149.15584]\n",
      " [186.35191]\n",
      " [179.99626]\n",
      " [194.71544]\n",
      " [145.14189]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 4.0802154541015625 \n",
      "Prediction :\n",
      "[[149.23073]\n",
      " [186.3003 ]\n",
      " [180.01892]\n",
      " [194.73412]\n",
      " [145.07224]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03. File input linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape : (25, 3), \tlen(x_data) : 25 \n",
      "x_data : \n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]]\n",
      "-------------------------\n",
      "y_data.shape : (25, 1)  \n",
      "y_data : \n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "xy = np.loadtxt('./data/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(\"x_data.shape : {}, \\tlen(x_data) : {} \\nx_data : \\n{}\".format(x_data.shape, len(x_data), x_data))\n",
    "print(\"-\"*25)\n",
    "print(\"y_data.shape : {}  \\ny_data : \\n{}\".format(y_data.shape, y_data))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 38.91928482055664 \n",
      "Prediction :\n",
      "[[159.03647 ]\n",
      " [190.77019 ]\n",
      " [188.05075 ]\n",
      " [205.023   ]\n",
      " [145.42569 ]\n",
      " [107.92775 ]\n",
      " [154.22163 ]\n",
      " [115.300354]\n",
      " [178.68732 ]\n",
      " [166.24567 ]\n",
      " [148.24973 ]\n",
      " [146.22989 ]\n",
      " [193.93015 ]\n",
      " [160.92294 ]\n",
      " [154.9333  ]\n",
      " [193.88336 ]\n",
      " [152.87361 ]\n",
      " [185.1226  ]\n",
      " [184.90878 ]\n",
      " [165.62753 ]\n",
      " [180.54524 ]\n",
      " [179.34142 ]\n",
      " [172.10834 ]\n",
      " [159.59805 ]\n",
      " [197.5581  ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 20.385709762573242 \n",
      "Prediction :\n",
      "[[157.03767 ]\n",
      " [188.36855 ]\n",
      " [185.68394 ]\n",
      " [202.44579 ]\n",
      " [143.59389 ]\n",
      " [106.577934]\n",
      " [152.2929  ]\n",
      " [113.87102 ]\n",
      " [176.44347 ]\n",
      " [164.16826 ]\n",
      " [146.39128 ]\n",
      " [144.39789 ]\n",
      " [191.48451 ]\n",
      " [158.8894  ]\n",
      " [152.99583 ]\n",
      " [191.44658 ]\n",
      " [150.93666 ]\n",
      " [182.808   ]\n",
      " [182.57706 ]\n",
      " [163.54118 ]\n",
      " [178.28343 ]\n",
      " [177.08868 ]\n",
      " [169.9517  ]\n",
      " [157.58185 ]\n",
      " [195.06877 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 13.53172492980957 \n",
      "Prediction :\n",
      "[[155.8221 ]\n",
      " [186.90825]\n",
      " [184.24469]\n",
      " [200.87872]\n",
      " [142.48003]\n",
      " [105.75742]\n",
      " [151.12027]\n",
      " [113.00222]\n",
      " [175.07936]\n",
      " [162.90572]\n",
      " [145.26134]\n",
      " [143.28421]\n",
      " [189.99718]\n",
      " [157.65247]\n",
      " [151.81798]\n",
      " [189.96503]\n",
      " [149.75839]\n",
      " [181.40083]\n",
      " [181.15892]\n",
      " [162.27228]\n",
      " [176.90833]\n",
      " [175.71907]\n",
      " [168.64047]\n",
      " [156.35535]\n",
      " [193.55505]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 10.99594497680664 \n",
      "Prediction :\n",
      "[[155.08275 ]\n",
      " [186.02036 ]\n",
      " [183.36942 ]\n",
      " [199.92587 ]\n",
      " [141.8027  ]\n",
      " [105.258766]\n",
      " [150.40741 ]\n",
      " [112.47427 ]\n",
      " [174.25021 ]\n",
      " [162.13864 ]\n",
      " [144.57434 ]\n",
      " [142.6073  ]\n",
      " [189.0925  ]\n",
      " [156.8999  ]\n",
      " [151.102   ]\n",
      " [189.06433 ]\n",
      " [149.04141 ]\n",
      " [180.54543 ]\n",
      " [180.29626 ]\n",
      " [161.50041 ]\n",
      " [176.07236 ]\n",
      " [174.88644 ]\n",
      " [167.84326 ]\n",
      " [155.60898 ]\n",
      " [192.63454 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 10.056744575500488 \n",
      "Prediction :\n",
      "[[154.63297]\n",
      " [185.48048]\n",
      " [182.83707]\n",
      " [199.3465 ]\n",
      " [141.39084]\n",
      " [104.9558 ]\n",
      " [149.97412]\n",
      " [112.15358]\n",
      " [173.74632]\n",
      " [161.67287]\n",
      " [144.15671]\n",
      " [142.19595]\n",
      " [188.54211]\n",
      " [156.44186]\n",
      " [150.66687]\n",
      " [188.5168 ]\n",
      " [148.60493]\n",
      " [180.02551]\n",
      " [179.77138]\n",
      " [161.03076]\n",
      " [175.56421]\n",
      " [174.38031]\n",
      " [167.35861]\n",
      " [155.15457]\n",
      " [192.07474]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 9.707871437072754 \n",
      "Prediction :\n",
      "[[154.35927 ]\n",
      " [185.15225 ]\n",
      " [182.51326 ]\n",
      " [198.99425 ]\n",
      " [141.14037 ]\n",
      " [104.771835]\n",
      " [149.71082 ]\n",
      " [111.9589  ]\n",
      " [173.44023 ]\n",
      " [161.39027 ]\n",
      " [143.90283 ]\n",
      " [141.94612 ]\n",
      " [188.20718 ]\n",
      " [156.1629  ]\n",
      " [150.40251 ]\n",
      " [188.18404 ]\n",
      " [148.33902 ]\n",
      " [179.70961 ]\n",
      " [179.45189 ]\n",
      " [160.74489 ]\n",
      " [175.25542 ]\n",
      " [174.07272 ]\n",
      " [167.06403 ]\n",
      " [154.87772 ]\n",
      " [191.73427 ]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 9.57723617553711 \n",
      "Prediction :\n",
      "[[154.19264]\n",
      " [184.95271]\n",
      " [182.31624]\n",
      " [198.78008]\n",
      " [140.98804]\n",
      " [104.66021]\n",
      " [149.55089]\n",
      " [111.84084]\n",
      " [173.25438]\n",
      " [161.2191 ]\n",
      " [143.74857]\n",
      " [141.79448]\n",
      " [188.00325]\n",
      " [155.99286]\n",
      " [150.242  ]\n",
      " [187.98186]\n",
      " [148.17682]\n",
      " [179.51775]\n",
      " [179.25728]\n",
      " [160.57076]\n",
      " [175.06784]\n",
      " [173.88588]\n",
      " [166.88503]\n",
      " [154.7088 ]\n",
      " [191.52716]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 9.527310371398926 \n",
      "Prediction :\n",
      "[[154.0911 ]\n",
      " [184.83139]\n",
      " [182.19632]\n",
      " [198.64984]\n",
      " [140.89536]\n",
      " [104.59259]\n",
      " [149.4538 ]\n",
      " [111.76938]\n",
      " [173.14166]\n",
      " [161.1156 ]\n",
      " [143.65482]\n",
      " [141.70251]\n",
      " [187.87894]\n",
      " [155.889  ]\n",
      " [150.1446 ]\n",
      " [187.85907]\n",
      " [148.07767]\n",
      " [179.4013 ]\n",
      " [179.13861]\n",
      " [160.46455]\n",
      " [174.95395]\n",
      " [173.7724 ]\n",
      " [166.77625]\n",
      " [154.60551]\n",
      " [191.40112]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 9.5072021484375 \n",
      "Prediction :\n",
      "[[154.02917]\n",
      " [184.75768]\n",
      " [182.12326]\n",
      " [198.57068]\n",
      " [140.839  ]\n",
      " [104.55173]\n",
      " [149.39493]\n",
      " [111.72626]\n",
      " [173.07343]\n",
      " [161.05334]\n",
      " [143.59792]\n",
      " [141.64688]\n",
      " [187.80307]\n",
      " [155.82544]\n",
      " [150.08562]\n",
      " [187.78456]\n",
      " [148.01686]\n",
      " [179.33075]\n",
      " [179.0661 ]\n",
      " [160.39969]\n",
      " [174.88487]\n",
      " [173.70358]\n",
      " [166.71022]\n",
      " [154.54214]\n",
      " [191.32443]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 9.49815559387207 \n",
      "Prediction :\n",
      "[[153.99129]\n",
      " [184.71289]\n",
      " [182.07872]\n",
      " [198.52255]\n",
      " [140.80469]\n",
      " [104.52712]\n",
      " [149.35928]\n",
      " [111.70034]\n",
      " [173.0322 ]\n",
      " [161.0161 ]\n",
      " [143.5634 ]\n",
      " [141.61331]\n",
      " [187.75667]\n",
      " [155.78633]\n",
      " [150.04997]\n",
      " [187.73941]\n",
      " [147.97937]\n",
      " [179.28806]\n",
      " [179.0217 ]\n",
      " [160.35992]\n",
      " [174.84305]\n",
      " [173.6619 ]\n",
      " [166.67017]\n",
      " [154.50305]\n",
      " [191.27771]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 9.2675199508667 \n",
      "Prediction :\n",
      "[[153.88588 ]\n",
      " [184.65067 ]\n",
      " [181.98131 ]\n",
      " [198.45169 ]\n",
      " [140.74419 ]\n",
      " [104.54431 ]\n",
      " [149.34047 ]\n",
      " [111.732346]\n",
      " [173.032   ]\n",
      " [161.09946 ]\n",
      " [143.52832 ]\n",
      " [141.62065 ]\n",
      " [187.62111 ]\n",
      " [155.6276  ]\n",
      " [150.04459 ]\n",
      " [187.70387 ]\n",
      " [147.80544 ]\n",
      " [179.2728  ]\n",
      " [178.87692 ]\n",
      " [160.22981 ]\n",
      " [174.81772 ]\n",
      " [173.63377 ]\n",
      " [166.63051 ]\n",
      " [154.3153  ]\n",
      " [191.18651 ]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 9.037360191345215 \n",
      "Prediction :\n",
      "[[153.83618]\n",
      " [184.65811]\n",
      " [181.95099]\n",
      " [198.45587]\n",
      " [140.73587]\n",
      " [104.60334]\n",
      " [149.37999]\n",
      " [111.81057]\n",
      " [173.09995]\n",
      " [161.25058]\n",
      " [143.54825]\n",
      " [141.68417]\n",
      " [187.55289]\n",
      " [155.52216]\n",
      " [150.09843]\n",
      " [187.74069]\n",
      " [147.68071]\n",
      " [179.32819]\n",
      " [178.79562]\n",
      " [160.15652]\n",
      " [174.8605 ]\n",
      " [173.67276]\n",
      " [166.655  ]\n",
      " [154.17912]\n",
      " [191.16617]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 8.825617790222168 \n",
      "Prediction :\n",
      "[[153.78894 ]\n",
      " [184.66489 ]\n",
      " [181.922   ]\n",
      " [198.45995 ]\n",
      " [140.72736 ]\n",
      " [104.65949 ]\n",
      " [149.41823 ]\n",
      " [111.886246]\n",
      " [173.16458 ]\n",
      " [161.39493 ]\n",
      " [143.56738 ]\n",
      " [141.74478 ]\n",
      " [187.48749 ]\n",
      " [155.42102 ]\n",
      " [150.1503  ]\n",
      " [187.7757  ]\n",
      " [147.56076 ]\n",
      " [179.38193 ]\n",
      " [178.7178  ]\n",
      " [160.08649 ]\n",
      " [174.90181 ]\n",
      " [173.70987 ]\n",
      " [166.67882 ]\n",
      " [154.04886 ]\n",
      " [191.1464  ]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 8.6308012008667 \n",
      "Prediction :\n",
      "[[153.74403]\n",
      " [184.671  ]\n",
      " [181.89429]\n",
      " [198.46399]\n",
      " [140.71869]\n",
      " [104.71288]\n",
      " [149.45526]\n",
      " [111.95947]\n",
      " [173.22604]\n",
      " [161.53285]\n",
      " [143.58582]\n",
      " [141.80255]\n",
      " [187.42484]\n",
      " [155.32396]\n",
      " [150.20026]\n",
      " [187.80898]\n",
      " [147.4454 ]\n",
      " [179.43408]\n",
      " [178.64339]\n",
      " [160.01959]\n",
      " [174.9417 ]\n",
      " [173.74516]\n",
      " [166.702  ]\n",
      " [153.92429]\n",
      " [191.12718]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 8.451495170593262 \n",
      "Prediction :\n",
      "[[153.70139]\n",
      " [184.67654]\n",
      " [181.86777]\n",
      " [198.46797]\n",
      " [140.70987]\n",
      " [104.76365]\n",
      " [149.49109]\n",
      " [112.03033]\n",
      " [173.28448]\n",
      " [161.66463]\n",
      " [143.60355]\n",
      " [141.85768]\n",
      " [187.3648 ]\n",
      " [155.23085]\n",
      " [150.24838]\n",
      " [187.84064]\n",
      " [147.33444]\n",
      " [179.48474]\n",
      " [178.57217]\n",
      " [159.95569]\n",
      " [174.98022]\n",
      " [173.77878]\n",
      " [166.72455]\n",
      " [153.80515]\n",
      " [191.10852]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 8.286449432373047 \n",
      "Prediction :\n",
      "[[153.66086]\n",
      " [184.68149]\n",
      " [181.84242]\n",
      " [198.47186]\n",
      " [140.70094]\n",
      " [104.81189]\n",
      " [149.5258 ]\n",
      " [112.0989 ]\n",
      " [173.34003]\n",
      " [161.7905 ]\n",
      " [143.62059]\n",
      " [141.91023]\n",
      " [187.30727]\n",
      " [155.14151]\n",
      " [150.29474]\n",
      " [187.87074]\n",
      " [147.22772]\n",
      " [179.53389]\n",
      " [178.50406]\n",
      " [159.89462]\n",
      " [175.01743]\n",
      " [173.81073]\n",
      " [166.74648]\n",
      " [153.6912 ]\n",
      " [191.09036]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 8.13451099395752 \n",
      "Prediction :\n",
      "[[153.62234]\n",
      " [184.68588]\n",
      " [181.81818]\n",
      " [198.47572]\n",
      " [140.69191]\n",
      " [104.85775]\n",
      " [149.5594 ]\n",
      " [112.16527]\n",
      " [173.39282]\n",
      " [161.91075]\n",
      " [143.63701]\n",
      " [141.96036]\n",
      " [187.25214]\n",
      " [155.05579]\n",
      " [150.33939]\n",
      " [187.89935]\n",
      " [147.12506]\n",
      " [179.5816 ]\n",
      " [178.43887]\n",
      " [159.8363 ]\n",
      " [175.05334]\n",
      " [173.84114]\n",
      " [166.76782]\n",
      " [153.58224]\n",
      " [191.07272]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 7.994580268859863 \n",
      "Prediction :\n",
      "[[153.5858 ]\n",
      " [184.68977]\n",
      " [181.795  ]\n",
      " [198.4795 ]\n",
      " [140.68277]\n",
      " [104.90134]\n",
      " [149.59193]\n",
      " [112.22951]\n",
      " [173.44298]\n",
      " [162.02562]\n",
      " [143.65279]\n",
      " [142.00813]\n",
      " [187.1993 ]\n",
      " [154.9735 ]\n",
      " [150.38243]\n",
      " [187.92656]\n",
      " [147.02629]\n",
      " [179.62794]\n",
      " [178.37651]\n",
      " [159.7806 ]\n",
      " [175.08807]\n",
      " [173.87006]\n",
      " [166.78857]\n",
      " [153.47801]\n",
      " [191.05557]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 7.865711212158203 \n",
      "Prediction :\n",
      "[[153.55109]\n",
      " [184.69318]\n",
      " [181.77283]\n",
      " [198.48322]\n",
      " [140.67357]\n",
      " [104.94276]\n",
      " [149.62344]\n",
      " [112.2917 ]\n",
      " [173.49063]\n",
      " [162.13535]\n",
      " [143.66797]\n",
      " [142.05368]\n",
      " [187.14865]\n",
      " [154.89456]\n",
      " [150.4239 ]\n",
      " [187.95241]\n",
      " [146.93126]\n",
      " [179.67291]\n",
      " [178.31683]\n",
      " [159.72736]\n",
      " [175.12161]\n",
      " [173.89755]\n",
      " [166.80878]\n",
      " [153.37836]\n",
      " [191.03888]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 7.746971607208252 \n",
      "Prediction :\n",
      "[[153.51814 ]\n",
      " [184.69615 ]\n",
      " [181.75163 ]\n",
      " [198.48686 ]\n",
      " [140.6643  ]\n",
      " [104.9821  ]\n",
      " [149.65395 ]\n",
      " [112.351906]\n",
      " [173.53593 ]\n",
      " [162.24016 ]\n",
      " [143.6826  ]\n",
      " [142.0971  ]\n",
      " [187.1001  ]\n",
      " [154.81877 ]\n",
      " [150.46385 ]\n",
      " [187.97696 ]\n",
      " [146.83981 ]\n",
      " [179.7166  ]\n",
      " [178.25975 ]\n",
      " [159.6765  ]\n",
      " [175.154   ]\n",
      " [173.9237  ]\n",
      " [166.82843 ]\n",
      " [153.28304 ]\n",
      " [191.02267 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.637568950653076 \n",
      "Prediction :\n",
      "[[153.48688]\n",
      " [184.6987 ]\n",
      " [181.73138]\n",
      " [198.49048]\n",
      " [140.65501]\n",
      " [105.01947]\n",
      " [149.6835 ]\n",
      " [112.41021]\n",
      " [173.57893]\n",
      " [162.34027]\n",
      " [143.69667]\n",
      " [142.13852]\n",
      " [187.05359]\n",
      " [154.74606]\n",
      " [150.50238]\n",
      " [188.0003 ]\n",
      " [146.75183]\n",
      " [179.75903]\n",
      " [178.20514]\n",
      " [159.62796]\n",
      " [175.18533]\n",
      " [173.94858]\n",
      " [166.84756]\n",
      " [153.1919 ]\n",
      " [191.00693]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 7.536721706390381 \n",
      "Prediction :\n",
      "[[153.4572  ]\n",
      " [184.70085 ]\n",
      " [181.71202 ]\n",
      " [198.494   ]\n",
      " [140.6457  ]\n",
      " [105.05496 ]\n",
      " [149.71214 ]\n",
      " [112.466644]\n",
      " [173.61978 ]\n",
      " [162.4359  ]\n",
      " [143.71022 ]\n",
      " [142.178   ]\n",
      " [187.009   ]\n",
      " [154.67625 ]\n",
      " [150.53952 ]\n",
      " [188.02248 ]\n",
      " [146.66716 ]\n",
      " [179.80022 ]\n",
      " [178.15291 ]\n",
      " [159.58159 ]\n",
      " [175.21559 ]\n",
      " [173.97221 ]\n",
      " [166.8662  ]\n",
      " [153.1047  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [190.99162 ]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 7.443758487701416 \n",
      "Prediction :\n",
      "[[153.42905 ]\n",
      " [184.7026  ]\n",
      " [181.69348 ]\n",
      " [198.49748 ]\n",
      " [140.63634 ]\n",
      " [105.088646]\n",
      " [149.73987 ]\n",
      " [112.52131 ]\n",
      " [173.65855 ]\n",
      " [162.52722 ]\n",
      " [143.72327 ]\n",
      " [142.2156  ]\n",
      " [186.96626 ]\n",
      " [154.60925 ]\n",
      " [150.57532 ]\n",
      " [188.04352 ]\n",
      " [146.58566 ]\n",
      " [179.84024 ]\n",
      " [178.1029  ]\n",
      " [159.53726 ]\n",
      " [175.24484 ]\n",
      " [173.99466 ]\n",
      " [166.88431 ]\n",
      " [153.02133 ]\n",
      " [190.97672 ]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 7.358026504516602 \n",
      "Prediction :\n",
      "[[153.40234]\n",
      " [184.70404]\n",
      " [181.67577]\n",
      " [198.50089]\n",
      " [140.62698]\n",
      " [105.12063]\n",
      " [149.76672]\n",
      " [112.57425]\n",
      " [173.69536]\n",
      " [162.61446]\n",
      " [143.73581]\n",
      " [142.25146]\n",
      " [186.9253 ]\n",
      " [154.54494]\n",
      " [150.6098 ]\n",
      " [188.0635 ]\n",
      " [146.50723]\n",
      " [179.87909]\n",
      " [178.05508]\n",
      " [159.49493]\n",
      " [175.2731 ]\n",
      " [174.016  ]\n",
      " [166.90193]\n",
      " [152.94159]\n",
      " [190.96223]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 7.278961181640625 \n",
      "Prediction :\n",
      "[[153.37704 ]\n",
      " [184.70514 ]\n",
      " [181.65884 ]\n",
      " [198.50424 ]\n",
      " [140.61763 ]\n",
      " [105.150986]\n",
      " [149.79279 ]\n",
      " [112.62552 ]\n",
      " [173.7303  ]\n",
      " [162.69778 ]\n",
      " [143.7479  ]\n",
      " [142.28561 ]\n",
      " [186.88602 ]\n",
      " [154.4832  ]\n",
      " [150.64308 ]\n",
      " [188.08249 ]\n",
      " [146.43173 ]\n",
      " [179.91684 ]\n",
      " [178.00932 ]\n",
      " [159.45454 ]\n",
      " [175.30043 ]\n",
      " [174.03629 ]\n",
      " [166.9191  ]\n",
      " [152.86536 ]\n",
      " [190.94815 ]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 7.206002235412598 \n",
      "Prediction :\n",
      "[[153.35303]\n",
      " [184.7059 ]\n",
      " [181.64264]\n",
      " [198.5075 ]\n",
      " [140.60828]\n",
      " [105.17979]\n",
      " [149.818  ]\n",
      " [112.67518]\n",
      " [173.76343]\n",
      " [162.77733]\n",
      " [143.75952]\n",
      " [142.31816]\n",
      " [186.84836]\n",
      " [154.4239 ]\n",
      " [150.67514]\n",
      " [188.1005 ]\n",
      " [146.35904]\n",
      " [179.95349]\n",
      " [177.96552]\n",
      " [159.41592]\n",
      " [175.32683]\n",
      " [174.05554]\n",
      " [166.93579]\n",
      " [152.79242]\n",
      " [190.93445]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 7.138690948486328 \n",
      "Prediction :\n",
      "[[153.33029]\n",
      " [184.7064 ]\n",
      " [181.62715]\n",
      " [198.51077]\n",
      " [140.59897]\n",
      " [105.20711]\n",
      " [149.84244]\n",
      " [112.7233 ]\n",
      " [173.79489]\n",
      " [162.85332]\n",
      " [143.77075]\n",
      " [142.34918]\n",
      " [186.81229]\n",
      " [154.367  ]\n",
      " [150.70609]\n",
      " [188.11758]\n",
      " [146.28905]\n",
      " [179.98912]\n",
      " [177.92365]\n",
      " [159.37907]\n",
      " [175.35239]\n",
      " [174.07382]\n",
      " [166.95206]\n",
      " [152.72269]\n",
      " [190.92114]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 7.076533794403076 \n",
      "Prediction :\n",
      "[[153.30875]\n",
      " [184.70663]\n",
      " [181.61234]\n",
      " [198.51393]\n",
      " [140.58966]\n",
      " [105.23301]\n",
      " [149.86613]\n",
      " [112.7699 ]\n",
      " [173.8247 ]\n",
      " [162.9259 ]\n",
      " [143.78152]\n",
      " [142.37872]\n",
      " [186.77768]\n",
      " [154.31235]\n",
      " [150.73592]\n",
      " [188.13379]\n",
      " [146.22166]\n",
      " [180.02374]\n",
      " [177.88354]\n",
      " [159.34387]\n",
      " [175.37708]\n",
      " [174.09122]\n",
      " [166.96788]\n",
      " [152.656  ]\n",
      " [190.90817]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 7.019164562225342 \n",
      "Prediction :\n",
      "[[153.28835]\n",
      " [184.70662]\n",
      " [181.59819]\n",
      " [198.51706]\n",
      " [140.58041]\n",
      " [105.25758]\n",
      " [149.8891 ]\n",
      " [112.81506]\n",
      " [173.85297]\n",
      " [162.9952 ]\n",
      " [143.79193]\n",
      " [142.40689]\n",
      " [186.7445 ]\n",
      " [154.25989]\n",
      " [150.76471]\n",
      " [188.14917]\n",
      " [146.1568 ]\n",
      " [180.05736]\n",
      " [177.84521]\n",
      " [159.31026]\n",
      " [175.40094]\n",
      " [174.1077 ]\n",
      " [166.98329]\n",
      " [152.59221]\n",
      " [190.8956 ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 6.966145038604736 \n",
      "Prediction :\n",
      "[[153.26901]\n",
      " [184.70638]\n",
      " [181.58466]\n",
      " [198.52011]\n",
      " [140.57123]\n",
      " [105.28086]\n",
      " [149.91135]\n",
      " [112.85882]\n",
      " [173.87978]\n",
      " [163.06137]\n",
      " [143.80194]\n",
      " [142.43369]\n",
      " [186.71269]\n",
      " [154.2095 ]\n",
      " [150.79245]\n",
      " [188.16376]\n",
      " [146.09431]\n",
      " [180.09003]\n",
      " [177.8085 ]\n",
      " [159.27815]\n",
      " [175.42406]\n",
      " [174.12335]\n",
      " [166.99829]\n",
      " [152.53122]\n",
      " [190.88333]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[185.65407]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[175.2043 ]\n",
      " [177.47295]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex04. TF reader linear regression 5\n",
    "> * 참조 : https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 11:11:48.027195  5428 deprecation.py:323] From <ipython-input-27-a7792e1f6310>:6: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:11:48.036959  5428 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:11:48.038953  5428 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0911 11:11:48.042821  5428 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:11:48.046726  5428 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:11:48.053607  5428 deprecation.py:323] From <ipython-input-27-a7792e1f6310>:8: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "W0911 11:11:48.061377  5428 deprecation.py:323] From <ipython-input-27-a7792e1f6310>:15: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "['./data/data-01-test-score.csv'], shuffle = False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "#####\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 11:11:54.913328  5428 deprecation.py:323] From <ipython-input-28-a0a2b752713a>:8: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf25098f42440d2ad3c56c241dba884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 25095.505859375 \n",
      "Prediction :\n",
      "[[ 10.050995 ]\n",
      " [ -1.170818 ]\n",
      " [  5.83598  ]\n",
      " [  4.515473 ]\n",
      " [ -2.690193 ]\n",
      " [ -6.4138255]\n",
      " [  4.329682 ]\n",
      " [  4.9393125]\n",
      " [ -6.4385524]\n",
      " [-11.244858 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 9730.7705078125 \n",
      "Prediction :\n",
      "[[54.609245]\n",
      " [47.31186 ]\n",
      " [76.704704]\n",
      " [65.472115]\n",
      " [56.91278 ]\n",
      " [67.138054]\n",
      " [60.472603]\n",
      " [72.51369 ]\n",
      " [75.44797 ]\n",
      " [68.594795]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 4275.7802734375 \n",
      "Prediction :\n",
      "[[108.96491 ]\n",
      " [102.65108 ]\n",
      " [105.52999 ]\n",
      " [107.63037 ]\n",
      " [117.397285]\n",
      " [102.87483 ]\n",
      " [110.43588 ]\n",
      " [115.78199 ]\n",
      " [124.264084]\n",
      " [ 82.43084 ]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1221.67724609375 \n",
      "Prediction :\n",
      "[[ 73.45798 ]\n",
      " [118.39084 ]\n",
      " [ 89.49651 ]\n",
      " [126.303734]\n",
      " [111.72764 ]\n",
      " [112.005775]\n",
      " [103.894264]\n",
      " [152.22308 ]\n",
      " [128.25899 ]\n",
      " [116.75539 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 603.8897094726562 \n",
      "Prediction :\n",
      "[[156.34215]\n",
      " [131.32742]\n",
      " [157.25002]\n",
      " [160.76607]\n",
      " [144.93405]\n",
      " [150.5473 ]\n",
      " [144.0718 ]\n",
      " [145.173  ]\n",
      " [144.64322]\n",
      " [163.14864]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 302.2217712402344 \n",
      "Prediction :\n",
      "[[148.58507]\n",
      " [165.39055]\n",
      " [169.92157]\n",
      " [183.2301 ]\n",
      " [124.34327]\n",
      " [ 87.26935]\n",
      " [138.10736]\n",
      " [104.1172 ]\n",
      " [149.25377]\n",
      " [132.9978 ]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 64.71339416503906 \n",
      "Prediction :\n",
      "[[136.16948]\n",
      " [127.73549]\n",
      " [183.98837]\n",
      " [154.65617]\n",
      " [141.95566]\n",
      " [174.08818]\n",
      " [145.41057]\n",
      " [174.10356]\n",
      " [177.72635]\n",
      " [160.10883]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 85.1057357788086 \n",
      "Prediction :\n",
      "[[169.03871]\n",
      " [162.49222]\n",
      " [162.80107]\n",
      " [161.0938 ]\n",
      " [183.49176]\n",
      " [155.9175 ]\n",
      " [174.21776]\n",
      " [178.61153]\n",
      " [192.69746]\n",
      " [131.07623]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 92.03401947021484 \n",
      "Prediction :\n",
      "[[ 93.639786]\n",
      " [147.19019 ]\n",
      " [110.85153 ]\n",
      " [159.83577 ]\n",
      " [142.81027 ]\n",
      " [139.75313 ]\n",
      " [131.27258 ]\n",
      " [188.69795 ]\n",
      " [158.56924 ]\n",
      " [145.69333 ]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 65.83895111083984 \n",
      "Prediction :\n",
      "[[180.84918]\n",
      " [150.76453]\n",
      " [180.52046]\n",
      " [184.17592]\n",
      " [165.87874]\n",
      " [173.28876]\n",
      " [166.72928]\n",
      " [166.85121]\n",
      " [164.8633 ]\n",
      " [188.16684]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 62.192771911621094 \n",
      "Prediction :\n",
      "[[160.68063]\n",
      " [180.47719]\n",
      " [184.4924 ]\n",
      " [199.23824]\n",
      " [135.87067]\n",
      " [ 96.04722]\n",
      " [150.14328]\n",
      " [113.09813]\n",
      " [163.65094]\n",
      " [146.69028]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 57.094993591308594 \n",
      "Prediction :\n",
      "[[160.37349 ]\n",
      " [180.65923 ]\n",
      " [184.37628 ]\n",
      " [199.25148 ]\n",
      " [136.03122 ]\n",
      " [ 96.44551 ]\n",
      " [150.20619 ]\n",
      " [113.202644]\n",
      " [164.11961 ]\n",
      " [147.48242 ]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 52.442596435546875 \n",
      "Prediction :\n",
      "[[160.07967]\n",
      " [180.8337 ]\n",
      " [184.26537]\n",
      " [199.26398]\n",
      " [136.18542]\n",
      " [ 96.82649]\n",
      " [150.26569]\n",
      " [113.30122]\n",
      " [164.56789]\n",
      " [148.23943]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 48.19674301147461 \n",
      "Prediction :\n",
      "[[159.79855]\n",
      " [181.00092]\n",
      " [184.1594 ]\n",
      " [199.27577]\n",
      " [136.33353]\n",
      " [ 97.19089]\n",
      " [150.32188]\n",
      " [113.39418]\n",
      " [164.99669]\n",
      " [148.96286]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 44.322242736816406 \n",
      "Prediction :\n",
      "[[159.52965]\n",
      " [181.16118]\n",
      " [184.05821]\n",
      " [199.28693]\n",
      " [136.47578]\n",
      " [ 97.53945]\n",
      " [150.37498]\n",
      " [113.4818 ]\n",
      " [165.40688]\n",
      " [149.65422]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 40.78672409057617 \n",
      "Prediction :\n",
      "[[159.27232]\n",
      " [181.31477]\n",
      " [183.96155]\n",
      " [199.29741]\n",
      " [136.61241]\n",
      " [ 97.87288]\n",
      " [150.4251 ]\n",
      " [113.56435]\n",
      " [165.79922]\n",
      " [150.31491]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 37.56071853637695 \n",
      "Prediction :\n",
      "[[159.02614]\n",
      " [181.462  ]\n",
      " [183.8692 ]\n",
      " [199.30733]\n",
      " [136.74368]\n",
      " [ 98.19182]\n",
      " [150.47238]\n",
      " [113.64206]\n",
      " [166.17456]\n",
      " [150.9463 ]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 34.6171875 \n",
      "Prediction :\n",
      "[[158.7906 ]\n",
      " [181.60315]\n",
      " [183.78102]\n",
      " [199.31667]\n",
      " [136.8698 ]\n",
      " [ 98.49693]\n",
      " [150.517  ]\n",
      " [113.71521]\n",
      " [166.53363]\n",
      " [151.54974]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 31.931726455688477 \n",
      "Prediction :\n",
      "[[158.5652 ]\n",
      " [181.73845]\n",
      " [183.69675]\n",
      " [199.32547]\n",
      " [136.99095]\n",
      " [ 98.7888 ]\n",
      " [150.55905]\n",
      " [113.78399]\n",
      " [166.8771 ]\n",
      " [152.1264 ]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 29.48172378540039 \n",
      "Prediction :\n",
      "[[158.34955]\n",
      " [181.86818]\n",
      " [183.61629]\n",
      " [199.33374]\n",
      " [137.10739]\n",
      " [ 99.06803]\n",
      " [150.59871]\n",
      " [113.84867]\n",
      " [167.2057 ]\n",
      " [152.67754]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 27.246692657470703 \n",
      "Prediction :\n",
      "[[158.14317 ]\n",
      " [181.99254 ]\n",
      " [183.53943 ]\n",
      " [199.34154 ]\n",
      " [137.21928 ]\n",
      " [ 99.33517 ]\n",
      " [150.63606 ]\n",
      " [113.909424]\n",
      " [167.5201  ]\n",
      " [153.20425 ]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 25.207965850830078 \n",
      "Prediction :\n",
      "[[157.9457 ]\n",
      " [182.1118 ]\n",
      " [183.46602]\n",
      " [199.34886]\n",
      " [137.32683]\n",
      " [ 99.59074]\n",
      " [150.67123]\n",
      " [113.96647]\n",
      " [167.82088]\n",
      " [153.70763]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 23.348453521728516 \n",
      "Prediction :\n",
      "[[157.75671]\n",
      " [182.22614]\n",
      " [183.39587]\n",
      " [199.35573]\n",
      " [137.43016]\n",
      " [ 99.83524]\n",
      " [150.70433]\n",
      " [114.01998]\n",
      " [168.10864]\n",
      " [154.1887 ]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 21.652511596679688 \n",
      "Prediction :\n",
      "[[157.57585]\n",
      " [182.33578]\n",
      " [183.32889]\n",
      " [199.3622 ]\n",
      " [137.52951]\n",
      " [100.06918]\n",
      " [150.73546]\n",
      " [114.07016]\n",
      " [168.38397]\n",
      " [154.64847]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 20.105783462524414 \n",
      "Prediction :\n",
      "[[157.40279 ]\n",
      " [182.44095 ]\n",
      " [183.26491 ]\n",
      " [199.3683  ]\n",
      " [137.62503 ]\n",
      " [100.29302 ]\n",
      " [150.76472 ]\n",
      " [114.117165]\n",
      " [168.64745 ]\n",
      " [155.08792 ]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 18.695419311523438 \n",
      "Prediction :\n",
      "[[157.23714 ]\n",
      " [182.5418  ]\n",
      " [183.2038  ]\n",
      " [199.37398 ]\n",
      " [137.71684 ]\n",
      " [100.507195]\n",
      " [150.79222 ]\n",
      " [114.16118 ]\n",
      " [168.89952 ]\n",
      " [155.50789 ]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 17.409404754638672 \n",
      "Prediction :\n",
      "[[157.0786 ]\n",
      " [182.63853]\n",
      " [183.14542]\n",
      " [199.37932]\n",
      " [137.80515]\n",
      " [100.71212]\n",
      " [150.81804]\n",
      " [114.20231]\n",
      " [169.14073]\n",
      " [155.90929]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 16.236942291259766 \n",
      "Prediction :\n",
      "[[156.92685 ]\n",
      " [182.73132 ]\n",
      " [183.08966 ]\n",
      " [199.38434 ]\n",
      " [137.89005 ]\n",
      " [100.90822 ]\n",
      " [150.84225 ]\n",
      " [114.240776]\n",
      " [169.37155 ]\n",
      " [156.29292 ]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 15.168116569519043 \n",
      "Prediction :\n",
      "[[156.7816  ]\n",
      " [182.82033 ]\n",
      " [183.03639 ]\n",
      " [199.38902 ]\n",
      " [137.97168 ]\n",
      " [101.09586 ]\n",
      " [150.86496 ]\n",
      " [114.276665]\n",
      " [169.59242 ]\n",
      " [156.65959 ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 14.193899154663086 \n",
      "Prediction :\n",
      "[[156.64258 ]\n",
      " [182.9057  ]\n",
      " [182.98552 ]\n",
      " [199.39339 ]\n",
      " [138.05019 ]\n",
      " [101.27542 ]\n",
      " [150.88622 ]\n",
      " [114.310135]\n",
      " [169.80379 ]\n",
      " [157.01003 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "Step_val = []\n",
    "Cost_val = []\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    \n",
    "\n",
    "    Step_val.append(step)\n",
    "    Cost_val.append(cost_val)\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,6]\n",
    "\n",
    "plt.plot(Step_val, Cost_val)\n",
    "plt.title('cost function')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('cost')\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[171.49309]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[169.43909]\n",
      " [185.52484]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
